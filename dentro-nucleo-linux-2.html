<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
 <META NAME="GENERATOR" CONTENT="LinuxDoc-Tools 0.9.21">
 <TITLE>Dentro del n&uacute;cleo Linux 2.4: Procesos y Manejo de Interrupciones</TITLE>
 <LINK HREF="dentro-nucleo-linux-3.html" REL=next>
 <LINK HREF="dentro-nucleo-linux-1.html" REL=previous>
 <LINK HREF="dentro-nucleo-linux.html#toc2" REL=contents>
</HEAD>
<BODY>
<A HREF="dentro-nucleo-linux-3.html">Página siguiente</A>
<A HREF="dentro-nucleo-linux-1.html">Página anterior</A>
<A HREF="dentro-nucleo-linux.html#toc2">Índice general</A>
<HR>
<H2><A NAME="s2">2.</A> <A HREF="dentro-nucleo-linux.html#toc2">Procesos y Manejo de Interrupciones</A></H2>



<H2><A NAME="ss2.1">2.1</A> <A HREF="dentro-nucleo-linux.html#toc2.1">Estructura de Tareas y Tabla de Procesos</A>
</H2>


<P>Cada proceso bajo Linux es din&aacute;micamente asignado a una estructura
<CODE>struct task_struct</CODE>. El n&uacute;mero m&aacute;ximo de procesos que pueden
ser creados bajo Linux est&aacute; solamente limitado por la cantidad de
memoria f&iacute;sica presente, y es igual a (ver
<CODE>kernel/fork.c:fork_init()</CODE>):</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
        /*
         * El n&uacute;mero m&aacute;ximo por defecto de hilos es establecido
         * a un valor seguro: las estructuras de hilos pueden ocupar al
         * menos la mitad de la memoria.
         */
        max_threads = mempages / (THREAD_SIZE/PAGE_SIZE) / 2;
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>lo cual, en la arquitectura IA32, b&aacute;sicamente significa
<CODE>num_physpages/4</CODE>. Como ejemplo, en una m&aacute;quina de 512M,
puedes crear 32k de hilos. Esto es una mejora considerable sobre el
l&iacute;mite de 4k-epsilon para los n&uacute;cleos viejos (2.2 y anteriores). Es
m&aacute;s, esto puede ser cambiado en tiempo de ejecuci&oacute;n usando el
KERN_MAX_THREADS <B>sysctl(2)</B>, o simplemente usando la interfaz
procfs para el ajuste del n&uacute;cleo:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
# cat /proc/sys/kernel/threads-max 
32764
# echo 100000 > /proc/sys/kernel/threads-max 
# cat /proc/sys/kernel/threads-max 
100000
# gdb -q vmlinux /proc/kcore
Core was generated by `BOOT_IMAGE=240ac18 ro root=306 video=matrox:vesa:0x118'.
#0  0x0 in ?? ()
(gdb) p max_threads
$1 = 100000
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>El conjunto de procesos en el sistema Linux est&aacute; representado como una
colecci&oacute;n de estructuras <CODE>struct task_struct</CODE>, las cuales est&aacute;n
enlazadas de dos formas:</P>
<P>
<OL>
<LI> como una tabla hash, ordenados por el pid, y</LI>
<LI> como una lista circular doblemente enlazada usando los punteros
<CODE>p->next_task</CODE> y <CODE>p->prev_task</CODE>.</LI>
</OL>
</P>
<P>La tabla hash es llamada <CODE>pidhash[]</CODE> y est&aacute; definida en
<CODE>include/linux/sched.h</CODE>:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
/* PID hashing. (¿no deber&iacute;a de ser din&aacute;mico?) */
#define PIDHASH_SZ (4096 >> 2)
extern struct task_struct *pidhash[PIDHASH_SZ];

#define pid_hashfn(x)   ((((x) >> 8) ^ (x)) &amp; (PIDHASH_SZ - 1))
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Las tareas son ordenadas por su valor pid y la posterior funci&oacute;n de
ordenaci&oacute;n se supone que distribuye los elementos uniformemente en sus
dominios de (<CODE>0</CODE> a <CODE>PID_MAX-1</CODE>). La tabla hash es usada para
encontrar r&aacute;pidamente una tarea por su pid usando
<CODE>find_task_pid()</CODE> dentro de <CODE>include/linux/sched.h</CODE>:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
static inline struct task_struct *find_task_by_pid(int pid)
{
        struct task_struct *p, **htable = &amp;pidhash[pid_hashfn(pid)];

        for(p = *htable; p &amp;&amp; p->pid != pid; p = p->pidhash_next)
                ;

        return p;
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Las tareas en cada lista ordenada (esto es, ordenadas por el mismo valor)
son enlazadas por <CODE>p->pidhash_next/pidhash_pprev</CODE> el cual es
usado por <CODE>hash_pid()</CODE> y <CODE>unhash_pid()</CODE> para insertar y
quitar un proceso dado en la tabla hash. Esto es realizado bajo la
protecci&oacute;n del spinlock read/write (lectura/escritura) llamado <CODE>tasklist_lock</CODE>
tomado para ESCRITURA.</P>
<P>La lista circular doblemente enlazada que usa
<CODE>p->next_task/prev_task</CODE> es mantenida para que uno pueda ir 
f&aacute;cilmente a trav&eacute;s de todas las tareas del sistema. Esto es realizado
por la macro <CODE>for_each_task()</CODE> desde
<CODE>include/linux/sched.h</CODE>:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
#define for_each_task(p) \
        for (p = &amp;init_task ; (p = p->next_task) != &amp;init_task ; )
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Los usuarios de <CODE>for_each_task()</CODE> deber&iacute;an de coger la
tasklist_lock para LECTURA. Destacar que <CODE>for_each_task()</CODE> est&aacute;
usando <CODE>init_task</CODE> para marcar el principio (y el final) de la
lista - esto es seguro porque la tarea vac&iacute;a (pid 0) nunca existe.</P>
<P>Los modificadores de los procesos de la tabla hash y/o los enlaces de la
tabla de procesos, notablemente <CODE>fork()</CODE>, <CODE>exit()</CODE> y
<CODE>ptrace()</CODE>, deben de coger la <CODE>tasklist_lock</CODE> para ESCRITURA.
El motivo por el que esto es interesante es porque los escritores deben
de deshabilitar las interrupciones en la CPU local. El motivo para esto
no es trivial: la funci&oacute;n <CODE>send_sigio()</CODE> anda por la lista  de
tareas y entonces coge <CODE>tasklist_lock</CODE> para ESCRITURA, y esta es llamada
desde <CODE>kill_fasync()</CODE> en el contexto de interrupciones. Este es
el motivo por el que los escritores deben de deshabilitar las
interrupciones mientras los lectores no lo necesitan.</P>
<P>Ahora que entendemos c&oacute;mo las estructuras <CODE>task_struct</CODE> son
enlazadas entre ellas, d&eacute;janos examinar los miembros de
<CODE>task_struct</CODE>. Ellos se corresponden d&eacute;bilmente con los 
miembros de las estructuras de UNIX 'struct proc' y 'struct user'
combinadas entre ellas.</P>
<P>Las otras versiones de UNIX separan la informaci&oacute;n del estado de las
tareas en una parte, la cual deber&aacute; de ser mantenida en memoria
residente durante todo el tiempo (llamada 'proc structure' la cual
incluye el estado del proceso, informaci&oacute;n de planificaci&oacute;n, etc.), y
otra parte, la cual es solamente necesitada cuando el proceso est&aacute;
funcionando (llamada 'u_area' la cual incluye la tabla de descriptores
de archivos, informaci&oacute;n sobre la cuota de disco etc.). El &uacute;nico motivo
para este feo dise&ntilde;o es que la memoria era un recurso muy escaso. Los
sistemas operativos modernos (bueno, s&oacute;lo Linux por el momento, pero
otros, como FreeBSD ( que parece que avanzan en esta direcci&oacute;n, hacia
Linux) no necesitan tal separaci&oacute;n y entonces mantienen el estado de
procesos en una estructura de datos del n&uacute;cleo residente en memoria
durante todo el tiempo.</P>
<P>La estructura task_struct est&aacute; declarada en
<CODE>include/linux/sched.h</CODE> y es actualmente de un tama&ntilde;o de 1680
bytes.</P>
<P>El campo de estado es declarado como:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
volatile long state;    /* -1 no ejecutable, 0 ejecutable, >0 parado */

#define TASK_RUNNING            0
#define TASK_INTERRUPTIBLE      1
#define TASK_UNINTERRUPTIBLE    2
#define TASK_ZOMBIE             4
#define TASK_STOPPED            8
#define TASK_EXCLUSIVE          32
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>¿Por qu&eacute; <CODE>TASK_EXCLUSIVE</CODE> est&aacute; definido como 32 y no c&oacute;mo 16?
Porque 16 fue usado por <CODE>TASK_SWAPPING</CODE> y me olvid&eacute; de
cambiar <CODE>TASK_EXCLUSIVE</CODE> cuando quit&eacute; todas las referencias
a <CODE>TASK_SWAPPING</CODE> (en alg&uacute;n sitio en 2.3.x).</P>
<P>La declaraci&oacute;n <CODE>volatile</CODE> en <CODE>p->state</CODE>significa que
puede ser modificada asincr&oacute;nicamente (desde el manejador de
interrupciones);</P>
<P>
<OL>
<LI><B>TASK_RUNNING</B>: significa que la tarea est&aacute;
"supuestamente" en la cola de ejecuci&oacute;n. El motivo por lo que quiz&aacute;s
no est&eacute; a&uacute;n en la cola de ejecuci&oacute;n es porque marcar una tarea como
<CODE>TASK_RUNNING</CODE> y colocarla en la cola de ejecuci&oacute;n no es
at&oacute;mico. Necesitar&aacute;s mantener el spinlock read/write
<CODE>runqueue_lock</CODE> en lectura para mirar en la cola de ejecuci&oacute;n.
Si lo haces, ver&aacute;s que cada tarea en la cola de ejecuci&oacute;n est&aacute; en el
estado <CODE>TASK_RUNNING</CODE>. Sin embargo, la conversi&oacute;n no es verdad
por los motivos explicados anteriormente. De una forma parecida, los
controladores pueden marcarse a ellos mismos (o en realidad, en el contexto
del proceso en el que est&aacute;n) como <CODE>TASK_INTERRUPTIBLE</CODE> (o 
<CODE>TASK_UNINTERRUPTIBLE</CODE>) y entonces llaman a 
<CODE>schedule()</CODE>, el cual entonces los quita de la cola de
ejecuci&oacute;n (a memos que exista una se&ntilde;al pendiente, en tal caso
permanecen en la cola de ejecuci&oacute;n). </LI>
<LI><B>TASK_INTERRUPTIBLE</B>: significa que la tarea est&aacute;
durmiendo pero que puede ser despertada por una se&ntilde;al o por la
terminaci&oacute;n de un cron&oacute;metro.</LI>
<LI><B>TASK_UNINTERRUPTIBLE</B>: lo mismo que
<CODE>TASK_INTERRUPTIBLE</CODE>, excepto que no puede ser
despertado.</LI>
<LI><B>TASK_ZOMBIE</B>: tareas que han terminado pero que no tienen
su estado reflejado (para <CODE>wait()</CODE>-ed) por el padre (natural o por
adopci&oacute;n).</LI>
<LI><B>TASK_STOPPED</B>: tarea que fue parada, por se&ntilde;ales de
control de trabajos o por <B>ptrace(2)</B>.</LI>
<LI><B>TASK_EXCLUSIVE</B>: este no es un estado separado pero puede
ser uno de <CODE>TASK_INTERRUPTIBLE</CODE> o <CODE>TASK_UNINTERRUPTIBLE</CODE>.
Esto significa que cuando esta tarea est&aacute; durmiendo o un una cola de
espera con otras tareas, puede ser despertada s&oacute;la en vez de causar
el problema de "movimiento general" despertando a todos los que est&aacute;n
esperando.</LI>
</OL>
</P>
<P>Las banderas de las tareas contienen informaci&oacute;n sobre los estados de
los procesos, los cuales no son mutuamente exclusivos:
<BLOCKQUOTE><CODE>
<HR>
<PRE>
unsigned long flags;    /* banderas para cada proceso, definidas abajo */
/*
 * Banderas para cada proceso
 */
#define PF_ALIGNWARN    0x00000001      /* Imprime mensajes de peligro de alineaci&oacute;n */
                                        /* No implementada todav&iacute;a, solo para 486 */
#define PF_STARTING     0x00000002      /* Durante la creaci&oacute;n */
#define PF_EXITING      0x00000004      /* Durante la destrucci&oacute;n */
#define PF_FORKNOEXEC   0x00000040      /* Dividido pero no ejecutado */
#define PF_SUPERPRIV    0x00000100      /* Usados privilegios de super-usuario */
#define PF_DUMPCORE     0x00000200      /* N&uacute;cleo volcado */
#define PF_SIGNALED     0x00000400      /* Asesinado por una se&ntilde;al */
#define PF_MEMALLOC     0x00000800      /* Asignando memoria */
#define PF_VFORK        0x00001000      /* Despertar al padre en mm_release */
#define PF_USEDFPU      0x00100000      /* La tarea us&oacute; de FPU este quantum (SMP) */
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Los campos <CODE>p->has_cpu</CODE>, <CODE>p->processor</CODE>, <CODE>p->counter</CODE>,
<CODE>p->priority</CODE>, <CODE>p->policy</CODE> y <CODE>p->rt_priority</CODE>
son referentes al planificador y ser&aacute;n mirados m&aacute;s tarde.</P>
<P>Los campos <CODE>p->mm</CODE> y <CODE>p->active_mm</CODE> apuntan
respectivamente a la direcci&oacute;n del espacio del proceso descrita por la
estructura <CODE>mm_struct</CODE> y al espacio activo de direcciones, si el
proceso no tiene una verdadera (ej, hilos de n&uacute;cleo). Esto ayuda a
minimizar las descargas TLB en los intercambios del espacio de
direcciones cuando la tarea es descargada. Por lo tanto, si nosotros
estamos planificando el hilo del n&uacute;cleo (el cual no tiene
<CODE>p->mm</CODE>) entonces su <CODE>next->active_mm</CODE> ser&aacute; establecido
al <CODE>prev->active_mm</CODE> de la tarea que fue descargada, la cual ser&aacute;
la misma que <CODE>prev->mm</CODE> si <CODE>prev->mm != NULL</CODE>. El espacio
de direcciones puede ser compartido entre hilos si la bandera
<CODE>CLONE_VM</CODE> es pasada a las llamadas al sistema <B>clone(2)</B>
o <B>vfork(2)</B>.</P>
<P>Los campos <CODE>p->exec_domain</CODE> y <CODE>p->personality</CODE> se refieren
a la personalidad de la tarea, esto es, la forma en que ciertas llamadas
al sistema se comportan para emular la "personalidad" de tipos
externos de UNIX.</P>
<P>El campo <CODE>p->fs</CODE> contiene informaci&oacute;n sobre el sistema de
archivos, lo cual significa bajo Linux tres partes de informaci&oacute;n:</P>
<P>
<OL>
<LI>dentry del directorio ra&iacute;z y punto de montaje,</LI>
<LI>dentry de un directorio ra&iacute;z alternativo y punto de montaje,</LI>
<LI>dentry del directorio de trabajo actual y punto de montaje.</LI>
</OL>
</P>
<P>Esta estructura tambi&eacute;n incluye un contador de referencia porque puede
ser compartido entre tareas clonadas cuando la bandera <CODE>CLONE_FS</CODE>
es pasada a la llamada al sistema <B>clone(2)</B>.</P>
<P>El campo <CODE>p->files</CODE> contiene la tabla de descriptores de
ficheros. Esto tambi&eacute;n puede ser compartido entre tareas, suministrando
<CODE>CLONE_FILES</CODE> el cual es especificado con <B>clone(2)</B>.</P>
<P>El campo <CODE>p->sig</CODE> contiene los manejadores de se&ntilde;ales y puede
ser compartido entre tareas clonadas por medio de
<CODE>CLONE_SIGHAND</CODE>.</P>

<H2><A NAME="ss2.2">2.2</A> <A HREF="dentro-nucleo-linux.html#toc2.2">Creaci&oacute;n y terminaci&oacute;n de tareas e hilos del n&uacute;cleo</A>
</H2>


<P>Diferentes libros sobre sistemas operativos definen un "proceso" de
diferentes formas, empezando por "instancia de un programa en
ejecuci&oacute;n" y finalizando con "lo que es producido por las llamadas del
sistema clone(2) o fork(2)". Bajo Linux, hay tres clases de procesos:</P>
<P>
<UL>
<LI> el/los hilo(s) vac&iacute;o(s),</LI>
<LI> hilos del n&uacute;cleo,</LI>
<LI> tareas de usuario.</LI>
</UL>
</P>
<P>El hilo vac&iacute;o es creado en tiempo de compilaci&oacute;n para la primera CPU;
es entonces creado "manualmente" para cada CPU por medio de la funci&oacute;n
espec&iacute;fica de la arquitectura <CODE>fork_by_hand()</CODE>  en
<CODE>arch/i386/kernel/smpboot.c</CODE>, el cual desenrolla la llamada al 
sistema <B>fork(2)</B> a mano (en algunas arquitecturas). Las tareas
vac&iacute;as comparten una estructura init_task pero tienen una estructura
privada TSS, en la matriz de cada CPU <CODE>init_tss</CODE>. Todas las
tareas vac&iacute;as tienen pid = 0 y ninguna otra tarea puede compartir el pid,
esto es, usar la bandera <CODE>CLONE_PID</CODE> en <B>clone(2)</B>.</P>
<P>Los hilos del n&uacute;cleo son creados usando la funci&oacute;n <CODE>kernel_thread()</CODE> 
la cual invoca a la llamada al sistema <B>clone(2)</B> en modo n&uacute;cleo.
Los hilos del n&uacute;cleo usualmente no tienen espacio de direcciones de
usuario, esto es <CODE>p->mm = NULL</CODE>, porque ellos explicitamente
hacen <CODE>exit_mm()</CODE>, ej. a trav&eacute;s de la funci&oacute;n
<CODE>daemonize()</CODE>. Los hilos del n&uacute;cleo siempre pueden acceder al
espacio de direcciones del n&uacute;cleo directamente. Ellos son asignados a
n&uacute;meros pid en el rango bajo. Funcionando en el anillo del procesador 0
(en x86) implica que los hilos del n&uacute;cleo disfrutan de todos
los privilegios de E/S y no pueden ser pre-desocupados por el
planificador.</P>
<P>Las tareas de usuario son creadas por medio de las llamadas al sistema
<B>clone(2)</B> o <B>fork(2)</B>, las cuales internamente invocan a
<B>kernel/fork.c:do_fork()</B>.</P>
<P>D&eacute;jenos entender qu&eacute; pasa cuando un proceso de usuario realiza una
llamada al sistema <B>fork(2)</B>. Como <B>fork(2)</B> es
dependiente de la arquitectura debido a las diferentes formas de pasar
la pila y registros de usuario, la actual funci&oacute;n subyacente
<CODE>do_fork()</CODE> que hace el trabajo es portable y est&aacute; localizada en
<CODE>kernel/fork.c</CODE>.</P>
<P>Los siguientes pasos son realizados:</P>
<P>
<OL>
<LI> La variable local <CODE>retval</CODE> es establecida a <CODE>-ENOMEM</CODE>,
ya que este es el valor al que <CODE>errno</CODE> deber&iacute;a de ser 
establecida si <B>fork(2)</B> falla al asignar una nueva
estructura de tarea.
</LI>
<LI> Si <CODE>CLONE_PID</CODE> es establecido en <CODE>clone_flags</CODE>
entonces devuelve un error (<CODE>-EPERM</CODE>), a menos que
el llamante sea el hilo vac&iacute;o (s&oacute;lo durante el arranque).
Por lo tanto, un hilo de un usuario normal no puede pasar 
<CODE>CLONE_PID</CODE> a <B>clone(2)</B> y esperar que tenga &eacute;xito.
Para <B>fork(2)</B>, es irrelevante que
<CODE>clone_flags</CODE> sea establecido a <CODE>SIFCHLD</CODE> - esto es
s&oacute;lo relevante cuando <CODE>do_fork()</CODE> es invocado desde
<CODE>sys_clone()</CODE> el cual pasa <CODE>clone_flags</CODE> desde el
valor pedido desde el espacio de usuario.
</LI>
<LI> <CODE>current->vfork_sem</CODE> es inicializado (es m&aacute;s tarde
limpiado en el hijo). Esto es usado por <CODE>sys_vfork()</CODE> (la
llamada al sistema <B>vfork(2)</B> corresponde a 
<CODE>clone_flags = CLONE_VFORK|CLONE_VM|SIGCHLD</CODE>) para hacer
que el padre duerma mientras el hijo hace <CODE>mm_release()</CODE>, 
por ejemplo como resultado de <CODE>exec()</CODE> (ejecutar) otro
programa o <B>exit(2)</B>.
</LI>
<LI> Una nueva estructura de tarea es asignada usando la macro 
dependiente de la arquitectura <CODE>alloc_task_struct()</CODE>. En
x86 es justo un gfp a la prioridad <CODE>GFP_KERNEL</CODE>. Este
es el primer motivo por el que la llamada <B>fork(2)</B>
quiz&aacute;s duerma. Si la primera asignaci&oacute;n falla, devolvemos
<CODE>-ENOMEM</CODE>.
</LI>
<LI> Todos los valores de la actual estructura de tareas del proceso
son copiadas en la nueva, usando un asignamiento de estructura
<CODE>*p = *current</CODE>. ¿Quiz&aacute;s deber&iacute;a de ser reemplazada
por un establecimiento de memoria? M&aacute;s tarde, los campos que no
deber&iacute;an de ser heredados por el hijo son establecidos a los
valores correctos.
</LI>
<LI> Un gran cierre del n&uacute;cleo es tomado durante el resto del c&oacute;digo
ya que en otro caso ser&iacute;a no reentrante.
</LI>
<LI> Si el padre no tiene recursos de usuario (un concepto de UID,
Linux es suficientemente flexible para hacer de ellos una
cuesti&oacute;n mejor que un hecho), entonces verifica si el l&iacute;mite
blando de usuario <CODE>RLIMIT_NPROC</CODE> ha sido excedido - si
lo es, falla con <CODE>-EAGAIN</CODE>, si no, incrementa la cuenta
de procesos con el uid dado <CODE>p->user->count</CODE>.
</LI>
<LI> Si el n&uacute;mero de tareas a lo largo del sistema excede el
valor de max_threads (recordar que es ajustable), falla con <CODE>-EAGAIN</CODE>.
</LI>
<LI> Si el binario que se ejecuta pertenece a un dominio
modularizado de ejecuci&oacute;n, incrementa el contador de referencia
del correspondiente m&oacute;dulo.
</LI>
<LI> Si el binario que se ejecuta pertenece a un formato binario
modularizado, incrementa el contador de referencia del m&oacute;dulo
correspondiente.
</LI>
<LI> El hijo es marcado como 'no tiene que ser ejecutado' (<CODE>p->did_exec = 0</CODE>)
</LI>
<LI> El hijo es marcado como 'no intercambiable' (<CODE>p->swappable = 0</CODE>)
</LI>
<LI> EL hijo es puesto en el estado 'durmiendo no interrumpible', esto es
<CODE>p->state = TASK_UNINTERRUPTIBLE</CODE> (POR HACER: ¿por qu&eacute; es
realizado esto? Creo que no se necesita - librarse de el, Linus 
confirma que no se necesita)
</LI>
<LI> Las <CODE>p->flags</CODE> del hijo son establecidas de acuerdo a los 
valores de clone_flags; para <B>fork(2)</B> limpias, esto ser&aacute;
<CODE>p->flags = PF_FORKNOEXEC</CODE>.
</LI>
<LI> El pid del hijo <CODE>p->pid</CODE> es establecido usando el
algoritmo r&aacute;pido en <CODE>kernel/fork.c:get_pid()</CODE> (POR HACER:
el spinlock <CODE>lastpid_lock</CODE> puede ser redundante ya que
<CODE>get_pid()</CODE> siempre es llamado bajo un gran cierre del
n&uacute;cleo desde <CODE>do_fork()</CODE>, tambi&eacute;n quita los argumentos
bandera de <CODE>get_pid()</CODE>, parche enviado a Alan el
20/06/2000 - mirar despu&eacute;s).
</LI>
<LI> El resto del c&oacute;digo en <CODE>do_fork()</CODE> inicializa el resto de
la estructura de la tarea del hijo. Muy al final, la estructura de
tarea del hijo es ordenada en la tabla hash <CODE>pidhash</CODE>  y
el hijo es despertado. (POR HACER: <CODE>wake_up_process(p)</CODE> 
establece <CODE>p->state = TASK_RUNNING</CODE> y a&ntilde;ade el proceso
a la cola de ejecuci&oacute;n, entonces probablemente no necesita
establecer <CODE>p->state</CODE> a <CODE>TASK_RUNNING</CODE>
tempranamente en <CODE>do_fork()</CODE>). La parte interesante es
establecer <CODE>p->exit_signal</CODE> a <CODE>clone_flags &amp;
CSIGNAL</CODE>, la cual para <B>fork(2)</B> significa justamente
<CODE>SIGCHLD</CODE> y establece <CODE>p->pdeath_signal</CODE> a 0.
La <CODE>pdeath_signal</CODE> es usada cuando un proceso 'olvida'
el padre original (durante la muerte) y puede ser
establecido/tomado por medio del comando <CODE>PR_GET/SET_PDEATHSIG</CODE>
de la llamada al sistema <B>prctl(2)</B> (Tu quiz&aacute;s argumentes
que la forma en la que el valor de <CODE>pdeath_signal</CODE> es 
devuelto a trav&eacute;s de un argumento de un puntero del espacio de
usuario en <B>prctl(2)</B> es un poco tonto - mea culpa, 
despu&eacute;s de que Andries Brouwer actualizara la p&aacute;gina man era
muy tarde para arreglarlo ;)</LI>
</OL>
</P>
<P>Entonces las tareas son creadas. Hay varias formas para la terminaci&oacute;n
de tareas:</P>
<P>
<OL>
<LI> haciendo la llamada al sistema <B>exit(2)</B>;
</LI>
<LI> enviando un se&ntilde;al con la disposici&oacute;n por defecto de morir;
</LI>
<LI> siendo forzado a morir bajo ciertas excepciones;
</LI>
<LI> llamando <B>bdflush(2)</B> con <CODE>func == 1</CODE> (esto es
espec&iacute;fico de Linux, para compatibilizaci&oacute;n de viejas distribuciones
que todav&iacute;a tienen la linea 'update' en <CODE>/etc/inittab</CODE> -
hoy en d&iacute;a el trabajo de update es hecho por el hilo del
n&uacute;cleo <CODE>kupdate</CODE>).
        </LI>
</OL>
</P>
<P>Las funciones implementando llamadas al sistema bajo Linux son
prefijadas con  <CODE>sys_</CODE>, pero ellas son usualmente concernientes
s&oacute;lo al chequeo de argumentos o a formas espec&iacute;ficas de la
arquitectura de pasar alguna informaci&oacute;n y el trabajo actual es
realizado por las funciones <CODE>do_</CODE>. Por lo tanto, es con
<CODE>sys_exit()</CODE> el cual llama a <CODE>do_exit()</CODE> para hacer el
trabajo. Aunque otras partes del n&uacute;cleo a veces invocan a
<CODE>sys_exit()</CODE> mientras que deber&iacute;an realmente de llamar a
<CODE>do_exit()</CODE>.</P>
<P>La funci&oacute;n <CODE>do_exit()</CODE> es encontrada en <CODE>kernel/exit.c</CODE>.
Los puntos que destacar sobre <CODE>do_exit()</CODE> son;</P>
<P>
<UL>
<LI> Usa un cierre global del n&uacute;cleo (cierra pero no abre).
</LI>
<LI> Llama <CODE>schedule()</CODE> al final, el cual nunca regresa.
</LI>
<LI> Establece el estado de tareas a <CODE>TASK_ZOMBIE</CODE>.
</LI>
<LI> Notifica cualquier hijo con <CODE>current->pdeath_signal</CODE>, si
no 0.
</LI>
<LI> Notifica al padre con una <CODE>current->exit_signal</CODE>, el cual
es usualmente igual a  <CODE>SIGCHLD</CODE>.
</LI>
<LI> Libera los recursos asignador por fork, cierra los archivos
abiertos, etc,
</LI>
<LI> En arquitecturas que usan FPU lentas (ia64, mips, mips64)
(POR HACER: quitar el argumento 'flags' de sparc, sparc64),
realiza lo que el hardware requiera para pasar la FPU al
due&ntilde;o (si el due&ntilde;o es el actual) a "none" (ninguno).</LI>
</UL>
</P>

<H2><A NAME="ss2.3">2.3</A> <A HREF="dentro-nucleo-linux.html#toc2.3">Planificador Linux</A>
</H2>


<P>El trabajo de un planificador es decidir el acceso a la actual CPU entre
m&uacute;ltiples procesos. El planificador est&aacute; implementado en el 'archivo
principal del n&uacute;cleo' <CODE>kernel/sched.c</CODE>. El archivo de cabeceras 
correspondiente <CODE>include/linux/sched.h</CODE> est&aacute; incluido virtualmente
(expl&iacute;cita o implicitamente) en todos los archivos de c&oacute;digo fuente del n&uacute;cleo.</P>
<P>Los campos de una estructura de tareas relevante a planificar incluyen:</P>
<P>
<UL>
<LI> <CODE>p->need_resched</CODE>: este campo es establecido si
<CODE>schedule()</CODE> deber&iacute;a de ser llamado en la 'siguiente
oportunidad'.
</LI>
<LI> <CODE>p->counter</CODE>: n&uacute;mero de ticks de reloj que quedan en esta
porci&oacute;n de tiempo del planificador, decrementada por un
cron&oacute;metro. Cuando este campo se convierte a un valor menor o
igual a cero, es reinicializado a 0 y <CODE>p->need_resched</CODE>
es establecido. Esto tambi&eacute;n es llamado a veces 'prioridad 
din&aacute;mica' de un proceso porque puede cambiarse a si mismo.
</LI>
<LI> <CODE>p->priority</CODE>: la prioridad est&aacute;tica del proceso, s&oacute;lo 
cambiada a trav&eacute;s de bien conocidas llamadas al sistema como
<B>nice(2)</B>, POSIX.1b <B>sched_setparam(2)</B> o
4.4BSD/SVR4 <B>setpriority(2)</B>.
</LI>
<LI> <CODE>p->rt_priority</CODE>: prioridad en tiempo real.
</LI>
<LI> <CODE>p->policy</CODE>: la pol&iacute;tica de planificaci&oacute;n, espec&iacute;fica a la
clase de planificaci&oacute;n que pertenece la tarea. Las tareas pueden
cambiar su clase de planificaci&oacute;n usando la llamada al sistema
<B>sched_setscheduler(2)</B>. Los valores v&aacute;lidos son
<CODE>SCHED_OTHER</CODE> (proceso UNIX tradicional),
<CODE>SCHED_FIFO</CODE> (proceso FIFO en tiempo real POSIX.1b) y 
<CODE>SCHED_RR</CODE> (proceso en tiempo real round-robin POSIX).
Uno puede tambi&eacute;n <CODE>SCHED_YIELD</CODE> a alguno de esos
valores para significar que el proceso decidi&oacute; dejar la CPU, por
ejemplo llamando a la llamada al sistema <B>sched_yield(2)</B>.
Un proceso FIFO en tiempo real funcionar&aacute; hasta que: a) se
bloquee en una E/S, b) expl&iacute;citamente deje la CPU, o c) es
predesocupado por otro proceso de tiempo real con un valor m&aacute;s
alto de <CODE>p->rt_priority</CODE>. <CODE>SCHED_RR</CODE> es el mismo
que <CODE>SCHED_FIFO</CODE>, excepto que cuando su porci&oacute;n de tiempo
acaba vuelve al final de la cola de ejecutables.</LI>
</UL>
</P>
<P>EL algoritmo de planificaci&oacute;n es simple, olv&iacute;date de la gran complejidad
aparente de la funci&oacute;n <CODE>schedule()</CODE>. La funci&oacute;n es compleja
porque implementa tres algoritmos de planificaci&oacute;n en uno y tambi&eacute;n
porque disimula los espec&iacute;ficos de SMP. </P>
<P>Las aparentemente 'inservibles' etiquetas (gotos) en <CODE>schedule()</CODE> est&aacute;n
all&iacute; con el prop&oacute;sito de generar el mejor c&oacute;digo optimizado (para
i386). Tambi&eacute;n, destacar que el planificador (como la mayor&iacute;a del
n&uacute;cleo) fue totalmente reescrito para el 2.4, entonces la discusi&oacute;n
de m&aacute;s abajo no se aplica a los n&uacute;cleos 2.2 o anteriores.</P>
<P>D&eacute;janos mirar la funci&oacute;n en detalle:</P>
<P>
<OL>
<LI> Si <CODE>current->active_mm == NULL</CODE> entonces algo est&aacute; mal.
El actual proceso, incluso un hilo del n&uacute;cleo 
(<CODE>current->mm == NULL</CODE>) debe de tener un <CODE>p->active_mm</CODE>
v&aacute;lido durante todo el tiempo.
</LI>
<LI> Si hay algo que hacer en la cola de tareas <CODE>tq_scheduler</CODE>,
entonces se procesa ahora. La cola de tareas suministra al 
n&uacute;cleo un mecanismo para planificar la ejecuci&oacute;n de las
funciones m&aacute;s tarde. Lo miraremos en detalle en otra parte.
</LI>
<LI> Se inicializan las variables locales <CODE>prev</CODE> y
<CODE>this_cpu</CODE> a las tareas y CPUs actuales, respectivamente.
</LI>
<LI> Se chequea si <CODE>schedule()</CODE> fue llamada desde el
controlador de interrupciones (debido a un fallo) y provoca un p&aacute;nico
si ha sido as&iacute;.
</LI>
<LI> Se quita el cierre global del n&uacute;cleo.
</LI>
<LI> Si hay alg&uacute;n trabajo que hacer a trav&eacute;s del mecanismo de
softirq, se hace ahora.
</LI>
<LI> Se inicializa el puntero local <CODE>struct schedule_data *sched_data</CODE>
para que apunte a cada CPU (alineado de la linea de antememoria para
prevenir que la linea de antememoria salte) planificando el
&aacute;rea de datos, el cual contiene el valor TSC de 
<CODE>last_schedule</CODE> y el puntero a la &uacute;ltima estructura
planificada (POR HACER: <CODE>sched_data</CODE> es usada s&oacute;lo en
SMP, ¿pero porqu&eacute; inicializa tambi&eacute;n <CODE>init_idle()</CODE> en UP (monoprocesadores)?
</LI>
<LI> Es tomado el spinlock <CODE>runqueue_lock</CODE>. Destacar que usamos
<CODE>spin_lock_irq()</CODE> porque en <CODE>schedule()</CODE>
garantizamos que las interrupciones est&aacute;n habilitadas. Por esto, 
cuando abrimos <CODE>runqueue_lock</CODE>, podemos
rehabilitarlas en vez de salvar/restaurar las eflags 
(variante <CODE>spin_lock_irqsave/restore</CODE>).
</LI>
<LI> Estado de tareas de la m&aacute;quina: si la tarea est&aacute; en el estado
<CODE>TASK_RUNNING</CODE> entonces se deja s&oacute;lo, si est&aacute; en el
estado <CODE>TASK_INTERRUPTIBLE</CODE> y hay una se&ntilde;al pendiente,
es movido al estado <CODE>TASK_RUNNING</CODE>. En todos los otros
casos es borrado de la cola de ejecuci&oacute;n.
</LI>
<LI> <CODE>next</CODE> (mejor candidato para ser planificado) es
establecido a la tarea vac&iacute;a de esta CPU. En todo caso, la
virtud de este candidato es establecida a un valor muy bajo 
(-1000), con la esperanza de que haya otro mejor que &eacute;l.
</LI>
<LI> Si la tarea <CODE>prev</CODE> (actual) est&aacute; en el estado
<CODE>TASK_RUNNING</CODE> entonces la actual virtud es establecida a
su virtud y es marcado como mejor candidato para ser 
planificado que la tarea vac&iacute;a.
</LI>
<LI> Ahora la cola de ejecuci&oacute;n es examinada y una virtud de cada
proceso que puede ser planificado en esta CPU es comparado
con el actual valor; el proceso con la virtud m&aacute;s alta gana.
Ahora el concepto de "puede ser planificado en esta CPU" debe
de ser clarificado: en UP, todos los procesos en la cola de
ejecuci&oacute;n son elegibles para ser planificados; en SMP, s&oacute;lo los
procesos que no estean corriendo en otra CPU son elegibles 
para ser planificados en esta CPU. La virtud es calculada por
una funci&oacute;n llamada <CODE>goodness()</CODE>, la cual trata los
procesos en tiempo real haciendo sus virtudes muy altas
(<CODE>1000 + p->rt_priority</CODE>), siendo mayor que 1000 se 
garantiza que no puede ganar otro proceso <CODE>SCHED_OTHER</CODE>;
por lo tanto s&oacute;lo compiten con los otros procesos en tiempo
real que quiz&aacute;s tengan un mayor <CODE>p->rt_priority</CODE>. La
funci&oacute;n virtud devuelve 0 si la porci&oacute;n de tiempo del proceso
(<CODE>p->counter</CODE>) se acab&oacute;. Para procesos que no son en
tiempo real, el valor inicial de la virtud es establecido a
<CODE>p->counter</CODE> - por este camino, el proceso tiene menos
posibilidades para alcanzar la CPU si ya la tuvo por alg&uacute;n tiempo,
esto es, los procesos interactivos son favorecidos m&aacute;s que 
el l&iacute;mite de impulsos de la CPU. La constante espec&iacute;fica de la
arquitectura <CODE>PROC_CHANGE_PENALTY</CODE> intenta implementar
la "afinidad de cpu" (esto es, dar ventaja a un proceso en la 
misma CPU). Tambi&eacute;n da una ligera ventaja a los procesos con
mm apuntando al actual <CODE>active_mm</CODE> o a procesos sin
espacio de direcciones (de usuario), esto es, hilos del n&uacute;cleo.
</LI>
<LI> si el actual valor de la virtud es 0 entonces la lista entera de
los procesos (¡no s&oacute;lo los de la lista de ejecutables!) es
examinada y sus prioridades din&aacute;micas son recalculadas usando
el simple algoritmo:

<BLOCKQUOTE><CODE>
<HR>
<PRE>

recalculate:
        {
                struct task_struct *p;
                spin_unlock_irq(&amp;runqueue_lock);
                read_lock(&amp;tasklist_lock);
                for_each_task(p)
                        p->counter = (p->counter >> 1) + p->priority;
                read_unlock(&amp;tasklist_lock);
                spin_lock_irq(&amp;runqueue_lock);
        }
</PRE>
<HR>
</CODE></BLOCKQUOTE>


Destacar que tiramos el <CODE>runqueue_lock</CODE> antes de
recalcular. El motivo para esto es que vamos a trav&eacute;s del
conjunto entero de procesos; esto puede llevar un gran
tiempo, durante el cual el <CODE>schedule()</CODE> puede ser
llamado por otra CPU y seleccionar un proceso con la
suficiente virtud para esta CPU, mientras que nosotros en
esta CPU seremos obligados a recalcular. Muy bien, admitamos
que esto es algo inconsistente porque mientras que nosotros
(en esta CPU) estamos seleccionando un proceso con la mejor
virtud, <CODE>schedule()</CODE> corriendo en otra CPU podr&iacute;a
estar recalculando las prioridades din&aacute;micas.
</LI>
<LI> Desde este punto, es cierto que <CODE>next</CODE> apunta a la tarea a
ser planificada, por lo tanto debemos de inicializar 
<CODE>next->has_cpu</CODE> a 1 y <CODE>next->processor</CODE> a
<CODE>this_cpu</CODE>. La <CODE>runqueue_lock</CODE> puede ahora ser
abierta.
</LI>
<LI> Si estamos volviendo a la misma tarea (<CODE>next == prev</CODE>)
entonces podemos simplemente readquirir un cierre global del
n&uacute;cleo y volver, esto es, saltar todos los niveles hardware
(registros, pila, etc.) y el grupo relacionado con la VM
(Memoria Virtual) (cambiar la p&aacute;gina del directorio, recalcular
<CODE>active_mm</CODE> etc.)
</LI>
<LI> La macro <CODE>switch_to()</CODE> es espec&iacute;fica de la arquitectura.
En i386, es concerniente con: a) manejo de la FPU (Unidad de Punto
Flotante), b) manejo de la LDT, c) recargar los registros de
segmento, d) manejo de TSS y e) recarga de los registros de
depuraci&oacute;n.
</LI>
</OL>
</P>

<H2><A NAME="ss2.4">2.4</A> <A HREF="dentro-nucleo-linux.html#toc2.4">Implementaci&oacute;n de la lista enlazada (de) Linux</A>
</H2>


<P>Antes de ir a examinar las implementaci&oacute;n de las colas de espera,
debemos de informarnos con la implementaci&oacute;n est&aacute;ndar de la lista
doblemente enlazada Linux. Las colas de espera (igual que todo lo dem&aacute;s
en Linux) hacen un uso fuerte de ellas y entonces son llamadas en
la jerga "implementaci&oacute;n list.h" porque el archivo m&aacute;s relevante es
<CODE>include/linux/list.h</CODE>.</P>
<P>La estructura de datos fundamental aqu&iacute; es <CODE>struct list_head</CODE>:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
struct list_head {
        struct list_head *next, *prev;
};

#define LIST_HEAD_INIT(name) { &amp;(name), &amp;(name) }

#define LIST_HEAD(name) \
        struct list_head name = LIST_HEAD_INIT(name)

#define INIT_LIST_HEAD(ptr) do { \
        (ptr)->next = (ptr); (ptr)->prev = (ptr); \
} while (0)

#define list_entry(ptr, type, member) \
        ((type *)((char *)(ptr)-(unsigned long)(&amp;((type *)0)->member)))

#define list_for_each(pos, head) \
        for (pos = (head)->next; pos != (head); pos = pos->next)
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Las tres primeras macros son para inicializar un lista vac&iacute;a apuntando
los punteros <CODE>next</CODE> y <CODE>prev</CODE> a ellos mismos. Esto es obvio
debido a las restricciones sint&aacute;cticas de C, las cuales deber&iacute;an de ser
usadas aqu&iacute; - por ejemplo, <CODE>LIST_HEAD_INIT()</CODE> puede ser usada
para la inicializaci&oacute;n de elementos de la estructura en la declaraci&oacute;n,
la segunda puede ser usada para la inicializaci&oacute;n de las declaraciones
de variables est&aacute;ticas y la tercera puede ser usada dentro de la
funci&oacute;n.</P>
<P>La macro <CODE>list_entry()</CODE> da acceso individual a los elementos 
de la lista, por ejemplo (desde
<CODE>fs/file_table.c:fs_may_remount_ro()</CODE>):</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
struct super_block {
   ...
   struct list_head s_files;
   ...
} *sb = &amp;some_super_block;

struct file {
   ...
   struct list_head f_list;
   ...
} *file;

struct list_head *p;

for (p = sb->s_files.next; p != &amp;sb->s_files; p = p->next) {
     struct file *file = list_entry(p, struct file, f_list);
     haz algo a 'file'
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Un buen ejemplo del uso de la macro <CODE>list_for_each()</CODE> est&aacute; en el
planificador, donde andamos a trav&eacute;s de la cola de ejecuci&oacute;n
buscando al proceso con la virtud m&aacute;s alta:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
static LIST_HEAD(runqueue_head);
struct list_head *tmp;
struct task_struct *p;

list_for_each(tmp, &amp;runqueue_head) {
    p = list_entry(tmp, struct task_struct, run_list);
    if (can_schedule(p)) {
        int weight = goodness(p, this_cpu, prev->active_mm);
        if (weight > c)
            c = weight, next = p;
    }
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Aqu&iacute;, <CODE>p->run_list</CODE> es declarada como <CODE>struct list_head
run_list</CODE> dentro de la estructura <CODE>task_struct</CODE> y sirve como
ancla de la lista. Quitando y a&ntilde;adiendo (al principio o al final de la lista)
un elemento de la lista es
hecho por las macros <CODE>list_del()/list_add()/list_add_tail()</CODE>. Los
ejemplos siguientes est&aacute;n a&ntilde;adiendo y quitando una tarea de la cola de
ejecuci&oacute;n:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
static inline void del_from_runqueue(struct task_struct * p)
{
        nr_running--;
        list_del(&amp;p->run_list);
        p->run_list.next = NULL;
}

static inline void add_to_runqueue(struct task_struct * p)
{
        list_add(&amp;p->run_list, &amp;runqueue_head);
        nr_running++;
}

static inline void move_last_runqueue(struct task_struct * p)
{
        list_del(&amp;p->run_list);
        list_add_tail(&amp;p->run_list, &amp;runqueue_head);
}

static inline void move_first_runqueue(struct task_struct * p)
{
        list_del(&amp;p->run_list);
        list_add(&amp;p->run_list, &amp;runqueue_head);
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>

<H2><A NAME="ss2.5">2.5</A> <A HREF="dentro-nucleo-linux.html#toc2.5">Colas de espera</A>
</H2>


<P>Cuando un proceso solicita el n&uacute;cleo para hacer algo que es
actualmente imposible pero que quiz&aacute;s sea posible m&aacute;s tarde, el
proceso es puesto a dormir y es despertado cuando la solicitud tiene
m&aacute;s probabilidades de ser satisfecha. Uno de los mecanismos del n&uacute;cleo
usados para esto es llamado 'cola de espera'. </P>
<P>La implementaci&oacute;n de Linux nos permite despertar usando la
bandera <CODE>TASK_EXCLUSIVE</CODE>. Con las colas de espera, tambi&eacute;n
puedes usar una cola bien conocida y entonces simplificar 
<CODE>sleep_on/sleep_on_timeout/interruptible_sleep_on/interruptible_sleep_on_timeout</CODE>,
o puedes definir tu propia cola de espera y usar
<CODE>add/remove_wait_queue</CODE> para a&ntilde;adir y quitarte desde ella y
<CODE>wake_up/wake_up_interruptible</CODE> para despertar cuando se
necesite.</P>
<P>Un ejemplo del primer uso de las colas de espera es la interacci&oacute;n
entre el asignador de p&aacute;ginas (en
<CODE>mm/page_alloc.c:__alloc_pages()</CODE>) y el demonio del n&uacute;cleo
<CODE>kswapd</CODE> (en <CODE>mm/vmscan.c:kswap()</CODE>), por medio de la
cola de espera <CODE>kswapd_wait,</CODE> declarada en <CODE>mm/vmscan.c</CODE>;
el demonio <CODE>kswapd</CODE> duerme en esta cola, y es despertado cuando
el asignador de p&aacute;ginas necesita liberar algunas p&aacute;ginas. </P>
<P>Un ejemplo del uso de una cola de espera aut&oacute;noma es la interacci&oacute;n
entre la solicitud de datos de un proceso de usuario a trav&eacute;s de la
llamada al sistema <B>read(2)</B> y el n&uacute;cleo funcionando en el
contexto de interrupci&oacute;n para suministrar los datos. Un manejador de
interrupciones quiz&aacute;s se parezca a 
(<CODE>drivers/char/rtc_interrupt()</CODE> simplificado):</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
static DECLARE_WAIT_QUEUE_HEAD(rtc_wait);

void rtc_interrupt(int irq, void *dev_id, struct pt_regs *regs)
{
        spin_lock(&amp;rtc_lock);       
        rtc_irq_data = CMOS_READ(RTC_INTR_FLAGS);
        spin_unlock(&amp;rtc_lock);     
        wake_up_interruptible(&amp;rtc_wait);
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Por lo tanto, el manejador de interrupciones obtiene los datos leyendo
desde alg&uacute;n puerto de E/S espec&iacute;fico del dispositivo (la macro
<CODE>CMOS_READ()</CODE> devuelve un par de <CODE>outb/inb</CODE>) y
entonces despierta a quien est&eacute; durmiendo en la cola de espera
<CODE>rtc_wait</CODE>.</P>
<P>Ahora, la llamada al sistema <B>read(2)</B> puede ser implementada
como:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
ssize_t rtc_read(struct file file, char *buf, size_t count, loff_t *ppos)
{
        DECLARE_WAITQUEUE(wait, current);
        unsigned long data;
        ssize_t retval;

        add_wait_queue(&amp;rtc_wait, &amp;wait);
        current->state = TASK_INTERRUPTIBLE;
        do {
                spin_lock_irq(&amp;rtc_lock);
                data = rtc_irq_data;
                rtc_irq_data = 0;
                spin_unlock_irq(&amp;rtc_lock);

                if (data != 0)
                        break;

                if (file->f_flags &amp; O_NONBLOCK) {
                        retval = -EAGAIN;
                        goto out;
                }
                if (signal_pending(current)) {
                        retval = -ERESTARTSYS;
                        goto out;
                }
                schedule();
        } while(1);
        retval = put_user(data, (unsigned long *)buf);  
        if (!retval)
                retval = sizeof(unsigned long);

out:
        current->state = TASK_RUNNING;
        remove_wait_queue(&amp;rtc_wait, &amp;wait);
        return retval;
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Lo que pasa en <CODE>rtc_read()</CODE> es esto:</P>
<P>
<OL>
<LI> Declaramos un elemento de la cola de espera apuntando al contexto
del proceso actual.
</LI>
<LI> A&ntilde;adimos este elemento a la cola de espera <CODE>rtc_wait</CODE>
</LI>
<LI> Marcamos el actual contexto como <CODE>TASK_INTERRUPTIBLE</CODE> lo
que significa que no ser&aacute; replanificado despu&eacute;s de la pr&oacute;xima
vez que duerma.
</LI>
<LI> Chequeamos si no hay datos disponibles; si los hay empezamos,
copiamos los datos a la memoria intermedia del usuario, nos marcamos como
<CODE>TASK_RUNNING</CODE>, nos quitamos de la cola de espera y
regresamos.
</LI>
<LI> Si todav&iacute;a no hay datos, chequeamos cuando el usuario especific&oacute;
una E/S no bloqueante, y si es as&iacute; entonces fallamos con
<CODE>EAGAIN</CODE> (el cual es el mismo que <CODE>EWOULDBLOCK</CODE>)
</LI>
<LI> Tambi&eacute;n chequeamos si hay alguna se&ntilde;al pendiente y si por lo
tanto informamos a las "capas superiores" para reinicializar
la llamada al sistema si es necesario. Por "si es necesario"
yo entiendo los detalles de la disposici&oacute;n de la se&ntilde;al tal
como est&aacute;n especificadas en la llamada al sistema
<B>sigaction(2)</B>.
</LI>
<LI> Entonces "salimos", esto es, nos dormimos, hasta que sea
despertado por el manejador de interrupciones. Si no nos
marcamos como <CODE>TASK_INTERRUPTIBLE</CODE> entonces el 
planificador nos podr&aacute; planificar tan pronto como los datos 
estean disponibles, causando as&iacute; procesamiento no necesario. </LI>
</OL>
</P>
<P>Es tambi&eacute;n valioso apuntar que, usando una cola de espera, es bastante
m&aacute;s f&aacute;cil implementar la llamada al sistema <B>poll(2)</B>:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
static unsigned int rtc_poll(struct file *file, poll_table *wait)
{
        unsigned long l;

        poll_wait(file, &amp;rtc_wait, wait);

        spin_lock_irq(&amp;rtc_lock);
        l = rtc_irq_data;
        spin_unlock_irq(&amp;rtc_lock);

        if (l != 0)
                return POLLIN | POLLRDNORM;
        return 0;
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Todo el trabajo es realizado por la funci&oacute;n independiente del
dispositivo <CODE>poll_wait()</CODE> la cual hace las manipulaciones
necesarias en la lista de espera; todo lo que necesitamos hacer es
apuntarla a la cola de espera la cual es despertada por nuestro manejador
de interrupciones espec&iacute;fico del dispositivo.</P>

<H2><A NAME="ss2.6">2.6</A> <A HREF="dentro-nucleo-linux.html#toc2.6">Cron&oacute;metros del n&uacute;cleo</A>
</H2>


<P>Ahora d&eacute;janos poner nuestra atenci&oacute;n en los cron&oacute;metros del n&uacute;cleo.
Los cron&oacute;metros del n&uacute;cleo son usados para expedir la ejecuci&oacute;n de
una funci&oacute;n particular (llamada 'manejador de cron&oacute;metros') en un
tiempo especificado en el futuro. La estructura de datos principal es 
<CODE>struct timer_list</CODE> declarada en <CODE>include/linux/timer.h</CODE>:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
struct timer_list {
        struct list_head list;
        unsigned long expires;
        unsigned long data;
        void (*function)(unsigned long);
        volatile int running;
};
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>El campo <CODE>list</CODE> es para enlazar con la lista interna, protegida
por el spinlock <CODE>timerlist_lock</CODE>. El campo <CODE>expires</CODE> es el
valor de <CODE>jiffies</CODE> cuando el manejador <CODE>function</CODE> deber&iacute;a
de ser invocado con <CODE>data</CODE> pasado como par&aacute;metro. El campo
<CODE>running</CODE> es usado en SMP para probar si el manejador de
cron&oacute;metros est&aacute; actualmente funcionando en otra CPU</P>
<P>Las funciones <CODE>add_timer()</CODE> y <CODE>del_timer()</CODE> a&ntilde;aden y
quitan un cron&oacute;metro determinado de la lista. Cuando un cron&oacute;metro se
termina, este es borrado autom&aacute;ticamente. Antes de que el cron&oacute;metro
sea usado, DEBE de ser inicializado por medio de la funci&oacute;n
<CODE>init_timer()</CODE>. Y entonces es a&ntilde;adido, los campos
<CODE>function</CODE> y <CODE>expires</CODE> deben de ser establecidos.</P>

<H2><A NAME="ss2.7">2.7</A> <A HREF="dentro-nucleo-linux.html#toc2.7">Bottom Halves</A>
</H2>


<P>A veces es razonable partir la cantidad de trabajo para ser realizada
dentro de un manejador de interrupciones en un trabajo inmediato (ej.
agradecer la interrupci&oacute;n, actualizar las estad&iacute;sticas, etc. ) y el
trabajo que puede ser postpuesto para m&aacute;s tarde, cuando las
interrupciones est&aacute;n habilitadas (ej, para realizar alg&uacute;n
post-procesamiento sobre los datos, despertar a los procesos esperando
por estos datos, etc).</P>
<P>Los bottom halves son el mecanismo m&aacute;s viejo para posponer la
ejecuci&oacute;n de una tarea del n&uacute;cleo y est&aacute;n disponibles desde Linux
1.x. En Linux 2.0, un nuevo mecanismo fue a&ntilde;adido, llamado 'colas de
tareas', las cuales ser&aacute;n el t&iacute;tulo de la siguiente secci&oacute;n.</P>
<P>Los bottom halves son serializados por el spinlock
<CODE>global_bh_lock</CODE>, esto es, s&oacute;lo puede haber un bottom half
funcionando en cualquier CPU a la vez. De cualquier modo, cuando se
intenta ejecutar el manejador, si no est&aacute; disponible
<CODE>global_bh_lock</CODE>, el bottom half es marcado (esto es
planificado) para ejecuci&oacute;n - por lo tanto el procesamiento puede
continuar, en opuesto a un bucle ocupado en <CODE>global_bh_lock</CODE>.</P>
<P>S&oacute;lo puede haber 32 bottom halves registrados en total. Las
funciones requeridas para manipular los bottom halves son las
siguientes (todas exportadas a m&oacute;dulos);</P>
<P>
<UL>
<LI> <CODE>void init_bh(int nr, void (*routine)(void))</CODE>: instala un
manejador de bottom half apuntado por el argumento
<CODE>routine</CODE> en el slot <CODE>nr</CODE>. El slot debe de estar 
numerado en <CODE>include/linux/interrupt.h</CODE> en la forma
<CODE>XXXX_BH</CODE>, ej. <CODE>TIMER_BH</CODE> o <CODE>TQUEUE_BH</CODE>. 
T&iacute;picamente, una rutina de inicializaci&oacute;n del subsistema
(<CODE>init_module()</CODE> para los m&oacute;dulos) instala el 
bottom half requerido usando esta funci&oacute;n.
</LI>
<LI> <CODE>void remove_bh(int nr)</CODE>: hace lo opuesto de
<CODE>init_bh()</CODE>, esto es, desinstala el bottom half
instalado en el slot <CODE>nr</CODE>. No hay chequeos de errores
realizados aqu&iacute;, por lo tanto, como ejemplo
<CODE>remove_bh(32)</CODE> rompe el sistema. T&iacute;picamente, una 
rutina de limpieza del subsistema (<CODE>cleanup_module()</CODE>
para los m&oacute;dulos) usa esta funci&oacute;n para liberar el slot, que
puede ser reusado por alg&uacute;n otro subsistema. (POR HACER: ¿no
ser&iacute;a bonito tener una lista <CODE>/proc/bottom_halves</CODE> con
todos los bottom halves en el sistema? Esto significa que
<CODE>global_bh_lock</CODE> deber&iacute;an hacer lecturas/escrituras,
obviamente).
</LI>
<LI> <CODE>void mark_bh(int nr)</CODE>: marca el bottom half en el slot 
<CODE>nr</CODE> para ejecuci&oacute;n. T&iacute;picamente, un manejador de
interrupciones marcar&aacute; este bottom half (¡de aqu&iacute; el nombre!)
para ejecuci&oacute;n en un "tiempo seguro".
</LI>
</UL>
</P>
<P>Los bottom halves son tasklets globalmente cerrados, por lo tanto la
pregunta "¿c&uacute;ando es el manejador bottom half ejecutado?" es realmente
"¿cu&aacute;ndo son los tasklets ejecutados?". Y la respuesta es, en dos
sitios: a) en cada <CODE>schedule()</CODE> y b) en cada camino de retorno de
interrupciones/llamadas al sistema en <CODE>entry.S</CODE> (POR HACER:
entonces, el caso <CODE>schedule()</CODE> es realmente aburrido - parece
a&ntilde;adir todav&iacute;a otra interrupci&oacute;n muy muy lenta, ¿por qu&eacute; no desembarazarse
de la etiqueta <CODE>handle_softirq</CODE> de <CODE>schedule()</CODE> en su
conjunto?). </P>

<H2><A NAME="ss2.8">2.8</A> <A HREF="dentro-nucleo-linux.html#toc2.8">Colas de Tareas</A>
</H2>


<P>Las colas de tareas pueden ser entendidas como una extensi&oacute;n din&aacute;mica
de los viejos bottom halves. En realidad, en el c&oacute;digo fuente son
a veces referidas como los "nuevos" bottom halves. M&aacute;s espec&iacute;ficamente,
los viejos bottom halves discutidos en la secci&oacute;n anterior tienen estas
limitaciones:</P>
<P>
<OL>
<LI> S&oacute;lo hay un n&uacute;mero fijo de ellos (32).
</LI>
<LI> Cada bottom half s&oacute;lo puede estar asociado con una funci&oacute;n de
manejador.
</LI>
<LI> Los Bottom halves son consumidos con un spinlock mantenido, por
lo tanto no pueden bloquear.</LI>
</OL>
</P>
<P>Por lo tanto, con las colas de tareas, un n&uacute;mero arbitrario de
funciones pueden ser encadenadas y procesadas una despu&eacute;s de otra en un
tiempo posterior. Uno crea una nueva cola de tareas usando la macro
<CODE>DECLARE_TASK_QUEUE()</CODE>  y encola la tarea en &eacute;l usando la
funci&oacute;n <CODE>queue_task()</CODE>. La cola de tareas entonces puede ser
procesada usando <CODE>run_task_queue()</CODE>. En vez de crear nuestra
propia cola de tareas (y tener que consumirla manualmente) puedes usar
una de las colas de tareas predefinidas en Linux las cuales son
consumidas en puntos bien conocidos:</P>
<P>
<OL>
<LI> <B>tq_timer</B>: la cola de tareas de cron&oacute;metros, funciona
en cada interrupci&oacute;n del cron&oacute;metro y cuando se libera un
dispositivo tty (cerrando o liberando un dispositivo de
terminal medio abierto). Desde que el manejador de cron&oacute;metro
funciona en el contexto de interrupci&oacute;n, la tarea <CODE>tq_timer</CODE>
tambi&eacute;n funciona en el contexto de interrupci&oacute;n y de este modo
tampoco puede bloquearse.
</LI>
<LI> <B>tq_scheduler</B>: la cola de tareas del planificador,
consumida por el planificador (y tambi&eacute;n cuando se cierran
dispositivos tty, como <CODE>tq_timer</CODE>). Como el
planificador es ejecutado en el contexto de los procesos siendo
re-planificados, las tareas <CODE>tq_scheduler</CODE> pueden hacer todo
lo que quieran, esto es bloquear, usar los datos del contexto de
los procesos (pero porque ellos quieren), etc .
</LI>
<LI> <B>tq_immediate</B>: esto es realmente un bottom half
<CODE>IMMEDIATE_BH</CODE>, por lo tanto los controladores pueden
<CODE>queue_task(task, &amp;tq_immediate)</CODE> y entonces
<CODE>mark_bh(IMMEDIATE_BH)</CODE> ser consumido en el contexto
de interrupci&oacute;n.
</LI>
<LI> <B>tq_disk</B>: usado por un acceso de dispositivo de bloqueo
de bajo nivel (y RAID) para empezar la actual petici&oacute;n. Esta
cola de tareas es exportada a los m&oacute;dulos pero no deber&iacute;a de
ser usada excepto para los prop&oacute;sitos especiales para los que
fue dise&ntilde;ada.    </LI>
</OL>
</P>
<P>A menos que un controlador use su propia cola de tareas, no necesita
llamar a <CODE>run_tasks_queues()</CODE> para procesar la cola, excepto bajo
ciertas circunstancias explicadas a continuaci&oacute;n.</P>
<P>El motivo por el que la cola de tareas <CODE>tq_timer/tq_scheduler</CODE> no es
consumida s&oacute;lo en los sitios usuales sino en otras partes (cerrando
un dispositivo tty, pero no el &uacute;nico ejemplo) se aclara
si uno recuerda que el controlador puede planificar tareas en la cola, y
estas tareas solo tienen sentido mientras una instancia particular del
dispositivo sea todav&iacute;a v&aacute;lida - lo cual usualmente significa hasta que la
aplicaci&oacute;n la cierre. Por lo tanto, el controlador quiz&aacute;s necesite
llamar a <CODE>run_task_queue()</CODE> para encender las tareas que el (y alguno
m&aacute;s) ha puesto en la  cola, porque permiti&eacute;ndoles funcionar en un
tiempo posterior quiz&aacute;s no tenga sentido - esto es, las estructuras de datos
relevantes quiz&aacute;s no hayan sido liberadas/reusadas por una instancia
diferente. Este es el motivo por el que ves <CODE>run_task_queue()</CODE> en
<CODE>tq_timer</CODE> y <CODE>tq_scheduler</CODE> en otros lugares m&aacute;s que el
cron&oacute;metro de interrupciones y <CODE>schedule()</CODE> respectivamente.</P>

<H2><A NAME="ss2.9">2.9</A> <A HREF="dentro-nucleo-linux.html#toc2.9">Tasklets</A>
</H2>


<P>Todav&iacute;a no, estar&aacute;n en una revisi&oacute;n futura</P>

<H2><A NAME="ss2.10">2.10</A> <A HREF="dentro-nucleo-linux.html#toc2.10">Softirqs</A>
</H2>


<P>Todav&iacute;a no, estar&aacute;n en una revisi&oacute;n futura</P>

<H2><A NAME="ss2.11">2.11</A> <A HREF="dentro-nucleo-linux.html#toc2.11">¿C&oacute;mo son las llamadas al sistema implementadas en la</A>
arquitectura i386?</H2>


<P>Existen dos mecanismos bajo Linux para implementar las llamadas al
sistema:</P>
<P>
<UL>
<LI> las llamadas puerta lcall7/lcall27 ;</LI>
<LI> interrupci&oacute;n software int 0x80.</LI>
</UL>
</P>
<P>Los programas nativos de Linux utilizan int 0x80 mientras que los
binarios de los distintos tipos de UNIX (Solaris, UnixWare 7 etc.) usan
el mecanismo lcall7. El nombre 'lcall7' es hist&oacute;ricamente enga&ntilde;oso
porque tambi&eacute;n cubre lcall27 (ej. Solaris/x86), pero la funci&oacute;n
manejadora es llamada lcall7_func. </P>
<P>Cuando el sistema arranca, la funci&oacute;n
<CODE>arch/i386/kernel/traps.c:trap_init()</CODE> es llamada, la cual
inicializa el IDT, por lo tanto el vector  0x80 (del tipo 15, dpl 3)
apunta a la direcci&oacute;n de la entrada system_call desde
<CODE>arch/i386/kernel/entry.S</CODE>.</P>
<P>Cuando una aplicaci&oacute;n del espacio de usuario realiza una llamada del
sistema, los argumentos son pasados a trav&eacute;s de los registros y la
aplicaci&oacute;n ejecuta la instrucci&oacute;n 'int 0x80'. Esto causa un reajuste en
el modo n&uacute;cleo y el procesador salta al punto de entrada system_call en
<CODE>entry.S</CODE>. Lo que esto hace es:</P>
<P>
<OL>
<LI> Guarda los registros.
</LI>
<LI> Establece %ds y %es a KERNEL_DS, por lo tanto todas las
referencias de datos (y segmentos extras) son hechas en el
espacio de direcciones del n&uacute;cleo.
</LI>
<LI> Si el valor de %eax es mayor que <CODE>NR_syscalls</CODE>
(actualmente 256) fallar&aacute; con el error <CODE>ENOSYS</CODE>.
</LI>
<LI> Si la tarea est&aacute; siendo ptraced (<CODE>tsk->ptrace &amp;
PF_TRACESYS</CODE>), realiza un procesamiento especial. Esto es
para soportar programas como strace (an&aacute;logo a SVR4 
<B>truss(1)</B>) o depuradores.
</LI>
<LI> Llamada <CODE>sys_call_table+4*(syscall_number desde %eax)</CODE>.
Esta tabla es inicializada en el mismo archivo
(<CODE>arch/i386/kernel/entry.S</CODE>) para apuntar a los
manejadores individuales de las llamadas al sistema, los cuales
bajo Linux son (usualmente) prefijados con <CODE>sys_</CODE>, ej. 
<CODE>sys_open</CODE>, <CODE>sys_exit</CODE>, etc. Estos manejadores de
las llamadas al sistema de C encontrar&aacute;n sus argumentos en la pila
donde <CODE>SAVE_ALL</CODE> las almacen&oacute;. 
</LI>
<LI> Entra en el 'camino de retorno de la llamada al sistema'. Esta es
una etiqueta separada porque es usada no s&oacute;lo por int 0x80 sino 
tambi&eacute;n por lcall7, lcall27. Esto es, relacionado con el
manejo de tasklets (incluyendo bottom halves), chequeando si
un <CODE>schedule()</CODE> es necesitado 
(<CODE>tsk->need_resched !=0</CODE>), chequeando si hay se&ntilde;ales
pendientes y por lo tanto manej&aacute;ndolas.</LI>
</OL>
</P>
<P>Linux soporta hasta 6 argumentos para las llamadas al sistema. Ellas
son pasadas en %ebx, %ecx, %edx, %esi, %edi (y %ebp usado temporalmente,
ver <CODE>_syscall6()</CODE> en <CODE>asm-i386/unistd.h</CODE>). El n&uacute;mero de
llamadas al sistema es pasado a trav&eacute;s de  %eax.</P>

<H2><A NAME="ss2.12">2.12</A> <A HREF="dentro-nucleo-linux.html#toc2.12">Operaciones At&oacute;micas</A>
</H2>


<P>Hay dos tipos de operaciones at&oacute;micas: bitmaps (mapas de bits) y
<CODE>atomic_t</CODE>. Los bitmaps son muy convenientes para mantener un
concepto de unidades "asignadas" o "libres" para alguna colecci&oacute;n
grande donde cada unidad es identificada por alg&uacute;n n&uacute;mero, por ejemplo
tres inodos o tres bloques. Son ampliamente usados para un simple
cierre, por ejemplo para suministrar acceso exclusivo para abrir un
dispositivo. Un ejemplo de esto puede ser encontrado en
<CODE>arch/i386/kernel/microcode.c</CODE>: </P>

<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
/*
 *  Bits en microcode_status. (31 bits de espacio para una futura expansi&oacute;n)
 */
#define MICROCODE_IS_OPEN       0       /* establece si el dispositivo est&aacute; en uso */

static unsigned long microcode_status;
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>No hay necesidad de inicializar <CODE>microcode_status</CODE> a 0 ya que BSS
es limpiado a cero expl&iacute;citamente bajo Linux.</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
/*
 * Forzamos a un s&oacute;lo usuario a la vez aqu&iacute; con open/close. 
 */
static int microcode_open(struct inode *inode, struct file *file)
{
        if (!capable(CAP_SYS_RAWIO))
                return -EPERM;

        /* uno de cada vez, por favor */
        if (test_and_set_bit(MICROCODE_IS_OPEN, &amp;microcode_status))
                return -EBUSY;

        MOD_INC_USE_COUNT;
        return 0;
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Las operaciones en los bitmaps son:</P>
<P>
<UL>
<LI> <B>void set_bit(int nr, volatile void *addr)</B>: establece el 
bit <CODE>nr</CODE> en el bitmap apuntado por <CODE>addr</CODE>.
</LI>
<LI> <B>void clear_bit(int nr, volatile void *addr)</B>: limpia el
bit <CODE>nr</CODE> en el bitmap apuntado por <CODE>addr</CODE>.
</LI>
<LI> <B>void change_bit(int nr, volatile void *addr)</B>: cambia el
bit <CODE>nr</CODE> (si est&aacute; establecido limpia, si est&aacute; limpio establece) en
en el bitmap apuntado por <CODE>addr</CODE>.
</LI>
<LI> <B>int test_and_set_bit(int nr, volatile void *addr)</B>:
at&oacute;micamente establece el bit <CODE>nr</CODE> y devuelve el
viejo valor del bit.
</LI>
<LI> <B>int test_and_clear_bit(int nr, volatile void *addr)</B>:
at&oacute;micamente limpia el bit <CODE>nr</CODE> y devuelve el viejo
valor del bit.
</LI>
<LI> <B>int test_and_change_bit(int nr, volatile void *addr)</B>:
at&oacute;micamente cambia el bit <CODE>nr</CODE> y devuelve el viejo
valor del bit.</LI>
</UL>
</P>
<P>Estas operaciones usan la macro <CODE>LOCK_PREFIX</CODE>, la cual en
n&uacute;cleos SMP eval&uacute;a la instrucci&oacute;n prefijo de cierre del bus y no
hace nada en UP. Esto garantiza la atomicidad del acceso en el entorno
SMP.</P>
<P>A veces las manipulaciones de bits no son convenientes, pero en cambio
necesitamos realizar operaciones aritm&eacute;ticas - suma, resta, incremento
decremento. Los casos t&iacute;picos son cuentas de referencia (ej. para los
inodos). Esta facilidad es suministrada por el tipo de datos
<CODE>atomic_t</CODE> y las siguientes operaciones:</P>
<P>
<UL>
<LI> <B>atomic_read(&amp;v)</B>: lee el valor de la variable
<CODE>atomic_t</CODE> <CODE>v</CODE>.
</LI>
<LI> <B>atomic_set(&amp;v, i)</B>: establece el valor de la
variable <CODE>atomic_t</CODE> <CODE>v</CODE> al entero <CODE>i</CODE>.
</LI>
<LI> <B>void atomic_add(int i, volatile atomic_t *v)</B>: suma 
un entero <CODE>i</CODE> al valor de la variable at&oacute;mica apuntado
por <CODE>v</CODE>.
</LI>
<LI> <B>void atomic_sub(int i, volatile atomic_t *v)</B>: resta
el entero <CODE>i</CODE> del valor de la variable at&oacute;mica apuntada
por <CODE>v</CODE>.
</LI>
<LI> <B>int atomic_sub_and_test(int i, volatile atomic_t *v)</B>:
resta el entero <CODE>i</CODE> del valor de la variable at&oacute;mica
apuntada por <CODE>v</CODE>; devuelve 1 si el nuevo valor es 0,
devuelve 0 en otro caso.
</LI>
<LI> <B>void atomic_inc(volatile atomic_t *v)</B>: incrementa el
valor en 1.
</LI>
<LI> <B>void atomic_dec(volatile atomic_t *v)</B>: decrementa el
valor en 1.
</LI>
<LI> <B>int atomic_dec_and_test(volatile atomic_t *v)</B>:
decrementa el valor; devuelve 1 si el nuevo valor es 0, 
devuelve 0 en otro caso.
</LI>
<LI> <B>int atomic_inc_and_test(volatile atomic_t *v)</B>:
incrementa el valor; devuelve 1 si el nuevo valor es 0, 
devuelve 0 en otro caso.
</LI>
<LI> <B>int atomic_add_negative(int i, volatile atomic_t *v)</B>:
suma el valor de <CODE>i</CODE> a <CODE>v</CODE> y devuelve 1 si el 
resultado es negativo. Devuelve 0 si el resultado es mayor o
igual a 0. Esta operaci&oacute;n es usada para implementar sem&aacute;foros.</LI>
</UL>
</P>

<H2><A NAME="ss2.13">2.13</A> <A HREF="dentro-nucleo-linux.html#toc2.13">Spinlocks, Spinlocks Read-Write y Spinlocks Big-Reader</A>
</H2>


<P>Desde los primeros d&iacute;as del soporte Linux (al principio de los 90, en
el siglo XX), los desarrolladores se encararon con el cl&aacute;sico problema
de acceder a datos compartidos entre los diferentes tipos de contexto
(procesos de usuario vs interrupciones) y diferentes instancias del
mismo contexto para m&uacute;ltiples cpus.</P>
<P>El soporte SMP fue a&ntilde;adido a Linux 1.3.42 el 15 de Noviembre de 1995
(el parche original fue hecho para el 1.3.37 en Octubre del mismo a&ntilde;o).</P>
<P>Si la regi&oacute;n cr&iacute;tica del c&oacute;digo puede ser ejecutada por el contexto
de los procesos y el contexto de las interrupciones, entonces la forma
de protegerlo usando las instrucciones <CODE>cli/sti</CODE> en UP es:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
unsigned long flags;

save_flags(flags);
cli();
/* c&oacute;digo cr&iacute;tico */
restore_flags(flags);
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Mientras que esto est&aacute; bien en UP, obviamente no lo est&aacute; us&aacute;ndolo en SMP
porque la misma secuencia de c&oacute;digo quiz&aacute;s sea  ejecutada
simult&aacute;neamente en otra cpu, y mientras <CODE>cli()</CODE> suministra
protecci&oacute;n contra las carreras con el contexto de interrupciones en
cada CPU individualmente, no suministra protecci&oacute;n contra todas las
carreras entre los contextos funcionando en diferentes CPUs. Es aqu&iacute;
donde los spinlocks son &uacute;tiles.</P>
<P>Hay tres tipos de spinlocks: vanilla (b&aacute;sico), read-write y
spinlocks big-reader. Los spinlocks read-write deber&iacute;an de ser
usados cuando existe una tendencia natural de 'muchos lectores y pocos
escritores'. Un ejemplo de esto es el acceso a las lista de sistemas de
archivos registrados (ver <CODE>fs/super.c</CODE>). La lista es
guardada por el spinlock read-write <CODE>file_systems_lock</CODE>
porque uno necesita acceso exclusivo s&oacute;lo cuando se est&aacute;
registrando/desregistrando un sistema de archivos, pero cualquier
proceso puede leer el archivo <CODE>/proc/filesystems</CODE> o usar la
llamada al sistema <B>sysfs(2)</B> para forzar un escaneo de s&oacute;lo
lectura de la lista file_systems. Esto lo hace sensible a usar spinlocks
read-write. Con los spinlocks read-write, uno puede tener
m&uacute;ltiples lectores a la vez pero s&oacute;lo un escritor y no puede haber
lectores mientras hay un escritor. Por el camino, ser&iacute;a bonito si nuevos
lectores no isaran un cierre mientras hay un escritor intentando
usar un cierre, esto es, si Linux pudiera distribuir correctamente
la soluci&oacute;n del hambre potencial del escritor por los m&uacute;ltiples
lectores. Esto quiere significar que los lectores deben de ser
bloqueados mientras exista un escritor intentando usar el cierre. Este
no es actualmente el caso y no es obvio cuando deber&iacute;a de ser arreglado
- el argumento para lo contrario es - los lectores usualmente ocupan el
cierre  por un instante de tiempo muy peque&ntilde;o, por lo tanto, ¿ellos
realmente deber&iacute;an de tener hambre mientras el escritor usa el cierre
para periodos potencialmente m&aacute;s largos?</P>
<P>Los spinlocks Big-reader son una forma de spinlocks read-write
altamente optimizados para accesos de lectura muy ligeros, con una
penalizaci&oacute;n para los escritores. Hay un n&uacute;mero limitado de
spinlocks big-reader - actualmente s&oacute;lo existen dos, de los cuales uno
es usado s&oacute;lo en sparc64 (irq global) y el otro es usado para redes. En
todos los dem&aacute;s casos donde el patr&oacute;n de acceso no concuerda con
ninguno de estos dos escenarios, se deber&iacute;a utilizar los spinlocks
b&aacute;sicos. No puedes bloquear mientras mantienes alg&uacute;n tipo de
spinlock.</P>
<P>Los Spinlocks vienen en tres tipos: plano, <CODE>_irq()</CODE> y <CODE>_bh()</CODE>.</P>
<P>
<OL>
<LI> <CODE>spin_lock()/spin_unlock()</CODE> plano: si conoces que las
interrupciones est&aacute;n siempre deshabilitadas o si no compites con el
contexto de interrupciones (ej. desde un manejador de interrupciones),
entonces puedes utilizar este. No toca el estado de interrupci&oacute;n en
la actual CPU.
</LI>
<LI> <CODE>spin_lock_irq()/spin_unlock_irq()</CODE>: si sabes que las
interrupciones est&aacute;n siempre habilitadas entonces puedes usar
esta versi&oacute;n, la cual simplemente deshabilita (en el cierre) y
re-habilita (en el desbloqueo) las interrupciones en la actual
CPU. Por ejemplo, <CODE>rtc_read()</CODE> usa
<CODE>spin_lock_irq(&amp;rtc_lock)</CODE>  (las interrupciones est&aacute;n
siempre habilitadas dentro de <CODE>read()</CODE>) mientras que 
<CODE>rtc_interrupt()</CODE> usa <CODE>spin_lock(&amp;rtc_lock)</CODE> 
(las interrupciones est&aacute;n siempre deshabilitadas dentro del
manejador de interrupciones). N&oacute;tese que <CODE>rtc_read()</CODE> usa
<CODE>spin_lock_irq()</CODE> y no el m&aacute;s gen&eacute;rico
<CODE>spin_lock_irqsave()</CODE> porque en la entrada a cualquier
llamada al sistema las interrupciones est&aacute;n siempre
habilitadas.
</LI>
<LI> <CODE>spin_lock_irqsave()/spin_unlock_irqrestore()</CODE>: la forma
m&aacute;s fuerte, es usada cuando el estado de las interrupciones no
es conocido, pero s&oacute;lo si las interrupciones no importan nada,
esto es, no hay punteros us&aacute;ndolo si nuestro manejador de
interrupciones no ejecuta ning&uacute;n c&oacute;digo cr&iacute;tico.</LI>
</OL>
</P>
<P>El motivo por el que no puedes usar el <CODE>spin_lock()</CODE> plano si
compites contra el manejador de interrupciones es porque si lo usas y
despu&eacute;s un interrupci&oacute;n viene en la misma CPU, el esperar&aacute; ocupado
por el bloqueo para siempre: el que tenga el bloqueo, habiendo sido
interrumpido, no continuar&aacute; hasta el que manejador de interrupciones
vuelva.</P>
<P>El uso m&aacute;s com&uacute;n de un spinlock es para acceder a estructuras de datos
compartidas entre el contexto de proceso de usuario y el manejador de
interrupciones:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
spinlock_t my_lock = SPIN_LOCK_UNLOCKED;

my_ioctl()
{
        spin_lock_irq(&amp;my_lock);
        /* secci&oacute;n cr&iacute;tica */
        spin_unlock_irq(&amp;my_lock);
}

my_irq_handler()
{
        spin_lock(&amp;lock);
        /* secci&oacute;n cr&iacute;tica */
        spin_unlock(&amp;lock);
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Hay un par de cosas que destacar sobre este ejemplo:</P>
<P>
<OL>
<LI> El contexto del proceso, representado aqu&iacute; como un m&eacute;todo
t&iacute;pico de un controlador - <CODE>ioctl()</CODE> (argumentos y 
valores de retorno omitidos para una mayor claridad), deben de
usar <CODE>spin_lock_irq()</CODE> porque conocen que las
interrupciones est&aacute;n siempre habilitadas mientras se ejecuta
un m&eacute;todo de dispositivo <CODE>ioctl()</CODE>.
</LI>
<LI> El contexto de interrupciones, representado aqu&iacute; por 
<CODE>my_irq_handler()</CODE> (otra vez los argumentos son omitidos para
una mayor claridad) pueden usar la forma <CODE>spin_lock()</CODE>
plana porque las interrupciones est&aacute;n deshabilitadas dentro del
manejador de interrupciones.</LI>
</OL>
</P>

<H2><A NAME="ss2.14">2.14</A> <A HREF="dentro-nucleo-linux.html#toc2.14">Sem&aacute;foros y sem&aacute;foros read/write</A>
</H2>


<P>A veces, mientras se est&aacute; accediendo a estructuras de datos
compartidas, uno debe realizar operaciones que puedan bloquear, por
ejemplo copiar datos al espacio de usuario. La directiva del cierre
disponible para tales escenarios bajo Linux es llamada sem&aacute;foro. Hay
dos tipos de sem&aacute;foros: b&aacute;sicos y sem&aacute;foros read/write.
Dependiendo del valor inicial del sem&aacute;foro, pueden ser usados
para exclusi&oacute;n mutua (valor inicial a 1) o para suministrar un tipo
m&aacute;s sofisticado de acceso.</P>
<P>Los sem&aacute;foros read-write difieren de los sem&aacute;foros b&aacute;sicos de la
misma forma que los spinlocks read-write difieren de los spinlocks
b&aacute;sicos: uno puede tener m&uacute;ltiples lectores a la vez pero s&oacute;lo un
escritor y no puede haber lectores mientras hay escritores - esto es, el
escritor bloquea a todos los lectores, y los nuevos lectores se bloquean
mientras un escritor est&aacute; esperando.</P>
<P>Tambi&eacute;n, los sem&aacute;foros b&aacute;sicos pueden ser interrumpidos - justamente
usan las operaciones <CODE>down/up_interruptible()</CODE> en vez del
<CODE>down()/up()</CODE> plano y chequean el valor devuelto desde
<CODE>down_interruptible()</CODE>: no ser&aacute; cero si la operaci&oacute;n fue
interrumpida.</P>
<P>El uso de sem&aacute;foros para exclusi&oacute;n mutua es ideal para situaciones donde
una secci&oacute;n cr&iacute;tica de c&oacute;digo quiz&aacute;s sea llamada por funciones de
referencia desconocidas registradas por otros subsistemas/m&oacute;dulos, esto
es, el llamante no conoce a priori cuando la funci&oacute;n bloquea o no.</P>
<P>Un ejemplo simple del uso de sem&aacute;foros est&aacute; en la implementaci&oacute;n de
las llamadas al sistema <B>gethostname(2)/sethostname(2)</B> en
<CODE>kernel/sys.c</CODE>.</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
asmlinkage long sys_sethostname(char *name, int len)
{
        int errno;

        if (!capable(CAP_SYS_ADMIN))
                return -EPERM;
        if (len &lt; 0 || len > __NEW_UTS_LEN)
                return -EINVAL;
        down_write(&amp;uts_sem);
        errno = -EFAULT;
        if (!copy_from_user(system_utsname.nodename, name, len)) {
                system_utsname.nodename[len] = 0;
                errno = 0;
        }
        up_write(&amp;uts_sem);
        return errno;
}

asmlinkage long sys_gethostname(char *name, int len)
{
        int i, errno;

        if (len &lt; 0)
                return -EINVAL;
        down_read(&amp;uts_sem);
        i = 1 + strlen(system_utsname.nodename);
        if (i > len)
                i = len;
        errno = 0;
        if (copy_to_user(name, system_utsname.nodename, i))
                errno = -EFAULT;
        up_read(&amp;uts_sem);
        return errno;
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Los puntos a destacar en este ejemplo son:</P>
<P>
<OL>
<LI> Las funciones quiz&aacute;s bloqueen mientras est&aacute;n copiando datos
desde/al espacio de usuario en 
<CODE>copy_from_user()/copy_to_user()</CODE>. Entonces no
pueden usar ninguna forma de spinlock aqu&iacute;.
</LI>
<LI> El tipo de sem&aacute;foro escogido es read-write en oposici&oacute;n
al b&aacute;sico porque quiz&aacute;s existan un mont&oacute;n de peticiones 
concurrentes <B>gethostname(2)</B> las cuales no tienen que
ser mutuamente exclusivas. </LI>
</OL>
</P>
<P>Aunque la implementaci&oacute;n de Linux de los sem&aacute;foros y los
sem&aacute;foros de read-write es muy sofisticada, existen posibles
escenarios que uno puede pensar en los cuales no est&aacute;n todav&iacute;a
implementados, por ejemplo, no existe el concepto de sem&aacute;foros
read-write interrumpible. Eso es obvio porque no hay situaciones
en el mundo real que requieran estos tipos ex&oacute;ticos de directivas.</P>

<H2><A NAME="ss2.15">2.15</A> <A HREF="dentro-nucleo-linux.html#toc2.15">Soporte del N&uacute;cleo para la Carga de M&oacute;dulos</A>
</H2>


<P>Linux es un sistema operativo monol&iacute;tico y olv&iacute;date de todos los dichos
modernos sobre algunas "ventajas" ofrecidas por los sistemas operativos
basados en el dise&ntilde;o micro-n&uacute;cleo, la verdad permanece (cita de
Linus Torvalds):</P>
<P>
<BLOCKQUOTE><CODE>
... el paso de mensajes como la operaci&oacute;n fundamental del SO es s&oacute;lo un
ejercicio de masturbaci&oacute;n de la ciencia de la computaci&oacute;n. Quiz&aacute;s
suene bien, pero actualmente no tienes nada HECHO.
</CODE></BLOCKQUOTE>
</P>
<P>Entonces, Linux esta y siempre estar&aacute; basado en un dise&ntilde;o monol&iacute;tico, lo
cual significa que todos los subsistemas funcionan en el mismo modo
privilegiado y comparten el mismo espacio de direcciones, la
comunicaci&oacute;n entre ellos es realizada por medio de las llamadas usuales
de funciones de C.</P>
<P>De cualquier modo, aunque la separaci&oacute;n de la funcionalidad del
n&uacute;cleo en "procesos" separados realizada en los micro-n&uacute;cleos es
definitivamente una mala idea, separ&aacute;ndolo en m&oacute;dulos del n&uacute;cleo
din&aacute;micamente cargados bajo demanda es deseable en algunas
circunstancias (ej, en m&aacute;quinas con poca memoria o para n&uacute;cleos de
instalaci&oacute;n, los cuales de otra forma pueden contener controladores de
dispositivos ISA auto-probables que son mutuamente exclusivos). La
decisi&oacute;n de cuando incluir soporte para la carga de m&oacute;dulos es hecha
en tiempo de compilaci&oacute;n y es determinada por la opci&oacute;n
<CODE>CONFIG_MODULES</CODE>. El soporte para la auto-carga de m&oacute;dulos a
trav&eacute;s del mecanismo <CODE>request_module()</CODE> es una opci&oacute;n separada
de compilaci&oacute;n (<CODE>CONFIG_KMOD</CODE>).</P>
<P>Las siguientes funcionalidades pueden ser implementadas como m&oacute;dulos
cargables bajo Linux:</P>
<P>
<OL>
<LI> Controladores de dispositivos de bloque y de car&aacute;cter, incluyendo
los controladores de dispositivos misc.
</LI>
<LI> Disciplinas de linea de Terminal.
</LI>
<LI> Ficheros virtuales (regulares) en <CODE>/proc</CODE> y en devfs
(ej. <CODE>/dev/cpu/microcode</CODE> vs <CODE>/dev/misc/microcode</CODE>).
</LI>
<LI> Formatos de Ficheros Binarios (ej. ELF, aout, etc).
</LI>
<LI> Dominios de Ejecuci&oacute;n (ej. Linux, UnixWare7, Solaris, etc).
</LI>
<LI> Sistemas de ficheros.
</LI>
<LI> System V IPC.</LI>
</OL>
</P>
<P>Hay unas pocas cosas que no pueden ser implementadas como m&oacute;dulos bajo
Linux (probablemente porque no tienen sentido el ser
modularizadas):</P>
<P>
<OL>
<LI> Algoritmos de planificaci&oacute;n.
</LI>
<LI> Pol&iacute;ticas de VM (Memoria Virtual).
</LI>
<LI> Antememoria intermedia, antememoria de p&aacute;ginas y otras antememoria.</LI>
</OL>
</P>
<P>Linux suministra varias llamadas al sistema para asistir en la carga de
m&oacute;dulos:</P>
<P>
<OL>
<LI><CODE>caddr_t create_module(const char *name, size_t size)</CODE>:
asigna <CODE>size</CODE> bytes usando <CODE>vmalloc()</CODE> y mapea una
estructura de un m&oacute;dulo al principio de este. Este nuevo m&oacute;dulo
es enlazado en la cabecera de la lista por module_list. S&oacute;lo
un proceso con <CODE>CAP_SYS_MODULE</CODE> puede llamar a esta 
llamada al sistema, otros ver&aacute;n como se les retorna
<CODE>EPERM</CODE>.
</LI>
<LI><CODE>long init_module(const char *name, struct module *image)</CODE>:
carga la imagen del m&oacute;dulo reasignado y motiva que la rutina de
inicializaci&oacute;n del m&oacute;dulo sea invocada. S&oacute;lo un proceso con
<CODE>CAP_SYS_MODULE</CODE> 
puede llamar a esta llamada al sistema, otros ver&aacute;n como se les 
retorna <CODE>EPERM</CODE>.
</LI>
<LI><CODE>long delete_module(const char *name)</CODE>: intenta descargar
el m&oacute;dulo.
Si <CODE>name == NULL</CODE>, el intento es hecho para descargar 
todos los m&oacute;dulos no utilizados.
</LI>
<LI><CODE>long query_module(const char *name, int which, void *buf, size_t bufsize, size_t *ret)</CODE>: devuelve informaci&oacute;n sobre un
m&oacute;dulo (o sobre todos los m&oacute;dulos). </LI>
</OL>
</P>
<P>La interfaz de comandos disponible a los usuarios consiste en:</P>
<P>
<UL>
<LI><B>insmod</B>: inserta un m&oacute;dulo simple.
</LI>
<LI><B>modprobe</B>: inserta un m&oacute;dulo incluyendo todos los otros
m&oacute;dulos de los cuales dependa.
          </LI>
<LI><B>rmmod</B>: quita un m&oacute;dulo.
</LI>
<LI><B>modinfo</B>: imprime alguna informaci&oacute;n sobre un m&oacute;dulo,
ej. autor, descripci&oacute;n, par&aacute;metros que acepta el m&oacute;dulo, etc. 
</LI>
</UL>
</P>
<P>Aparte de ser capaz de cargar un m&oacute;dulo manualmente usando
<B>insmod</B> o <B>modprobe</B>, tambi&eacute;n es posible tener el
m&oacute;dulo insertado autom&aacute;ticamente por el n&uacute;cleo cuando una
funcionalidad particular es requerida. La interface del n&uacute;cleo para
esto es la funci&oacute;n llamada <CODE>request_module(name)</CODE> la cual es
exportada a los m&oacute;dulos, por lo tanto los m&oacute;dulos tambi&eacute;n pueden
cargar otros m&oacute;dulos. La <CODE>request_module(name)</CODE> internamente
crea un hilo del n&uacute;cleo el cual ejecuta el comando del espacio de
usuario <B>modprobe -s -k module_name</B>, usando la interfaz
est&aacute;ndar del n&uacute;cleo <CODE>exec_usermodehelper()</CODE> (que es tambi&eacute;n
exportado a los m&oacute;dulos). La funci&oacute;n devuelve 0 si es exitosa, de
cualquier forma no es usualmente v&aacute;lido chequear el c&oacute;digo de
retorno desde <CODE>request_module()</CODE>. En vez de esto, el idioma de
programaci&oacute;n es:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
if (check_some_feature() == NULL)
    request_module(module);
if (check_some_feature() == NULL)
    return -ENODEV;
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Por ejemplo, esto es realizado por <CODE>fs/block_dev.c:get_blkfops()</CODE>
para cargar un m&oacute;dulo <CODE>block-major-N</CODE> cuando el intento es hecho
para abrir un dispositivo de bloque con n&uacute;mero mayor <CODE>N</CODE>.
Obviamente, no existe tal m&oacute;dulo llamado <CODE>block-major-N</CODE> (los
desarrolladores Linux solo escogen nombres sensibles para sus m&oacute;dulos)
pero es mapeado al propio nombre del m&oacute;dulo usando el archivo
<CODE>/etc/modules.conf</CODE>. De cualquier forma, para la mayor&iacute;a de los
n&uacute;meros mayores bien conocidos (y otros tipos de m&oacute;dulos) los comandos
<B>modprobe/insmod</B> conocen qu&eacute; m&oacute;dulo real cargar sin necesitar
una declaraci&oacute;n expl&iacute;cita de un alias en <CODE>/etc/modules.conf</CODE>.</P>
<P>Un buen ejemplo de la carga de un m&oacute;dulo est&aacute; dentro de la llamada del
sistema <B>mount(2)</B>. La llamada al sistema <B>mount(2)</B>
acepta el tipo de sistema de archivos como una cadena
<CODE>fs/super.c:do_mount()</CODE>  la cual entonces pasa a
<CODE>fs/super.c:get_fs_type()</CODE>:</P>
<P>
<BLOCKQUOTE><CODE>
<HR>
<PRE>
static struct file_system_type *get_fs_type(const char *name)
{
        struct file_system_type *fs;

        read_lock(&amp;file_systems_lock);
        fs = *(find_filesystem(name));
        if (fs &amp;&amp; !try_inc_mod_count(fs->owner))
                fs = NULL;
        read_unlock(&amp;file_systems_lock);
        if (!fs &amp;&amp; (request_module(name) == 0)) {
                read_lock(&amp;file_systems_lock);
                fs = *(find_filesystem(name));
                if (fs &amp;&amp; !try_inc_mod_count(fs->owner))
                        fs = NULL;
                read_unlock(&amp;file_systems_lock);
        }
        return fs;
}
</PRE>
<HR>
</CODE></BLOCKQUOTE>
</P>
<P>Hay que destacar unas pocas cosas en esta funci&oacute;n:</P>
<P>
<OL>
<LI> Primero intentamos encontrar el sistema de archivos con el nombre
dado entre aquellos ya registrados. Esto es hecho bajo la
protecci&oacute;n de <CODE>file_systems_lock</CODE>  tomado para lectura
(ya que no estamos modificando la lista registrada de 
sistemas de archivos).
</LI>
<LI> Si tal sistema de archivos es encontrado intentamos coger una
nueva referencia a &eacute;l intentando incrementar la cuenta mantenida
del m&oacute;dulo. Esto siempre devuelve 1 para sistemas de archivos
enlazados din&aacute;micamente o para m&oacute;dulos que actualmente no se han
borrados. Si <CODE>try_inc_mod_count()</CODE> devuelve 0 entonces
lo consideraremos un fallo - esto es, si el m&oacute;dulo est&aacute; all&iacute;
pero est&aacute; siendo borrado, es tan bueno como si no estuviera
all&iacute; en absoluto.
</LI>
<LI> Tiramos el <CODE>file_systems_lock</CODE> porque lo siguiente
que vamos a hacer (<CODE>request_module()</CODE>) es una operaci&oacute;n
bloqueante, y entonces no podemos mantener un spinlock sobre el.
Actualmente, en este caso espec&iacute;fico, podr&iacute;amos tirar
<CODE>file_systems_lock</CODE> de cualquier forma, incluso si
<CODE>request_module()</CODE> fuera garantizada para ser no
bloqueante y la carga de m&oacute;dulos fuera ejecutada en el mismo 
contexto at&oacute;micamente. El motivo para esto es que la funci&oacute;n
de inicializaci&oacute;n de m&oacute;dulos intentar&aacute; llamar a
<CODE>register_filesystem()</CODE>, la cual tomar&aacute; el mismo
spinlock read-write <CODE>file_systems_lock</CODE> para
escritura.
</LI>
<LI> Si el intento de carga tiene &eacute;xito, entonces cogemos el spinlock
<CODE>file_systems_lock</CODE> e intentamos situar el nuevamente 
registrado sistema de archivos en la lista. N&oacute;tese que esto es
ligeramente err&oacute;neo porque es posible en un principio que un
fallo en el comando modprobe pueda causar un volcado del n&uacute;cleo despu&eacute;s de
cargar con &eacute;xito el m&oacute;dulo pedido, en tal caso
<CODE>request_module()</CODE> fallar&aacute; incluso aunque el nuevo
sistema de archivos halla sido registrado, y todav&iacute;a no lo
encontrar&aacute; <CODE>get_fs_type()</CODE>.
 </LI>
<LI> Si el sistema de archivos es encontrado y  es capaz de obtener
una referencia a el, la devolvemos. En otro caso devolvemos NULL.</LI>
</OL>
</P>
<P>Cuando un m&oacute;dulo es cargado en el n&uacute;cleo, puede ser referido por
cualquier s&iacute;mbolo que sea exportado como p&uacute;blico por el n&uacute;cleo usando
la macro <CODE>EXPORT_SYMBOL()</CODE> o por otros m&oacute;dulos actualmente
cargados. Si el m&oacute;dulo usa s&iacute;mbolos de otro m&oacute;dulo, es marcado como
dependiente de ese m&oacute;dulo durante el rec&aacute;lculo de dependencias,
realizado funcionando el comando <B>depmod -a</B> en el arranque (ej.
despu&eacute;s de instalar un nuevo n&uacute;cleo).</P>
<P>Usualmente, uno debe comprobar el conjunto de los m&oacute;dulos con la
versi&oacute;n de las interfaces del n&uacute;cleo que usan, lo cual bajo
Linux simplemente significa la "versi&oacute;n del n&uacute;cleo" ya que no hay
versionados especiales del mecanismo de interfaces del n&uacute;cleo en
general. De cualquier forma, hay una funcionalidad limitada llamada
"versionamiento de m&oacute;dulos" o <CODE>CONFIG_MODVERSIONS</CODE> la cual nos
permite eliminar el recompilamiento de m&oacute;dulos cuando cambiamos a un
nuevo n&uacute;cleo. Lo que pasa aqu&iacute; es que la tabla de s&iacute;mbolos de n&uacute;cleo
es tratada de forma diferente para el acceso interno y para el acceso de
los m&oacute;dulos. Los elementos de la parte p&uacute;blica (exportada) de la tabla
de s&iacute;mbolos son construidos en la declaraci&oacute;n de C de suma de control
32bit. Por lo tanto, en orden de resolver un s&iacute;mbolo usado por un
m&oacute;dulo durante la carga, el cargador debe comprobar la representaci&oacute;n
total del s&iacute;mbolo que incluye la suma de control; ser&aacute; rechazada para
cargar el m&oacute;dulo si estos s&iacute;mbolos difieren. Esto s&oacute;lo pasa cuando el
n&uacute;cleo y el m&oacute;dulo son compilados con el versionamiento de m&oacute;dulos
habilitado. Si ninguno de los dos usa los nombres originales de los
s&iacute;mbolos el cargador simplemente intenta comprobar la versi&oacute;n del
n&uacute;cleo declarada por el m&oacute;dulo y el exportado por el n&uacute;cleo y rechaza
cargarlo si difieren.</P>

<HR>
<A HREF="dentro-nucleo-linux-3.html">Página siguiente</A>
<A HREF="dentro-nucleo-linux-1.html">Página anterior</A>
<A HREF="dentro-nucleo-linux.html#toc2">Índice general</A>
</BODY>
</HTML>
